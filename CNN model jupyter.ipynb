{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835edc3f-8637-4993-a0a3-85ad496e0aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c05d2dea-0a6e-4176-90b4-8c068b548b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Rescaling(1.0 / 255, input_shape=(180, 180, 3)),  # Normalize the image\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(2)  # Output layer for red and green percentages\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd48f36-e80f-4814-8afd-6aeae8271e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Image\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img_resized = cv2.resize(img, (180, 180))  # Resize to 180x180\n",
    "    img_normalized = img_resized / 255.0  # Normalize pixel values to [0, 1]\n",
    "    return img_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "352b5f45-e0ce-42c3-bd11-09711aee09b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Image for Red/Green Percentages\n",
    "def process_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    grid_HSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define HSV ranges for red and green\n",
    "    lower_red1 = np.array([0, 150, 50])\n",
    "    upper_red1 = np.array([30, 255, 255])\n",
    "    lower_red2 = np.array([170, 150, 50])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "    lower_green = np.array([15, 100, 50])\n",
    "    upper_green = np.array([105, 255, 255])\n",
    "\n",
    "    # Create masks for red and green\n",
    "    red_mask1 = cv2.inRange(grid_HSV, lower_red1, upper_red1)\n",
    "    red_mask2 = cv2.inRange(grid_HSV, lower_red2, upper_red2)\n",
    "    red_mask = cv2.bitwise_or(red_mask1, red_mask2)\n",
    "\n",
    "    green_mask = cv2.inRange(grid_HSV, lower_green, upper_green)\n",
    "\n",
    "    # Count non-zero pixels\n",
    "    red_pixels = cv2.countNonZero(red_mask)\n",
    "    green_pixels = cv2.countNonZero(green_mask)\n",
    "    total_color_pixels = red_pixels + green_pixels\n",
    "\n",
    "    percentage_red = (red_pixels / total_color_pixels) * 100 if total_color_pixels > 0 else 0\n",
    "    percentage_green = (green_pixels / total_color_pixels) * 100 if total_color_pixels > 0 else 0\n",
    "\n",
    "    return percentage_red, percentage_green\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23be7d5c-64aa-418c-a5f1-a3c10a827465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "def train_model(image_folder):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    # Traverse through image_folder and subdirectories\n",
    "    for root, _, files in os.walk(image_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "                image_path = os.path.join(root, file)\n",
    "                red_percentage, green_percentage = process_image(image_path)\n",
    "\n",
    "                image_paths.append(image_path)\n",
    "                labels.append([red_percentage, green_percentage])\n",
    "\n",
    "    # Debugging step\n",
    "    print(f\"Loaded {len(image_paths)} images.\")\n",
    "\n",
    "    if not image_paths:\n",
    "        raise ValueError(\"No images found in the specified folder.\")\n",
    "\n",
    "    # Preprocess images\n",
    "    images = np.array([preprocess_image(path) for path in image_paths])  # Shape: (num_samples, 180, 180, 3)\n",
    "    labels = np.array(labels)  # Shape: (num_samples, 2)\n",
    "\n",
    "    print(f\"Images shape: {images.shape}, Labels shape: {labels.shape}\")\n",
    "    \n",
    "    model = create_model()\n",
    "    model.fit(images, labels, epochs=40, batch_size=32)\n",
    "\n",
    "    # Save the trained model\n",
    "    model.save(\"red_green_model_with_percentages.h5\")\n",
    "    print(\"Model saved as red_green_model_with_percentages.h5\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9d0dbd8-3733-46d9-a37d-a3640591a661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 194 images.\n",
      "Images shape: (194, 180, 180, 3), Labels shape: (194, 2)\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/40\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "7/7 [==============================] - 11s 961ms/step - loss: 4521.4639 - accuracy: 0.5670\n",
      "Epoch 2/40\n",
      "7/7 [==============================] - 7s 928ms/step - loss: 2643.0491 - accuracy: 0.6082\n",
      "Epoch 3/40\n",
      "7/7 [==============================] - 7s 914ms/step - loss: 2244.2839 - accuracy: 0.6082\n",
      "Epoch 4/40\n",
      "7/7 [==============================] - 7s 962ms/step - loss: 2216.0859 - accuracy: 0.6082\n",
      "Epoch 5/40\n",
      "7/7 [==============================] - 7s 931ms/step - loss: 2210.9495 - accuracy: 0.6082\n",
      "Epoch 6/40\n",
      "7/7 [==============================] - 7s 911ms/step - loss: 2204.7397 - accuracy: 0.5258\n",
      "Epoch 7/40\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2143.1228 - accuracy: 0.6082\n",
      "Epoch 8/40\n",
      "7/7 [==============================] - 8s 975ms/step - loss: 2131.7534 - accuracy: 0.6082\n",
      "Epoch 9/40\n",
      "7/7 [==============================] - 7s 925ms/step - loss: 2168.7190 - accuracy: 0.6082\n",
      "Epoch 10/40\n",
      "7/7 [==============================] - 7s 917ms/step - loss: 2154.0154 - accuracy: 0.6082\n",
      "Epoch 11/40\n",
      "7/7 [==============================] - 7s 922ms/step - loss: 2151.5754 - accuracy: 0.6082\n",
      "Epoch 12/40\n",
      "7/7 [==============================] - 7s 933ms/step - loss: 2155.2341 - accuracy: 0.6082\n",
      "Epoch 13/40\n",
      "7/7 [==============================] - 7s 915ms/step - loss: 2184.5808 - accuracy: 0.5052\n",
      "Epoch 14/40\n",
      "7/7 [==============================] - 7s 906ms/step - loss: 2201.5598 - accuracy: 0.4330\n",
      "Epoch 15/40\n",
      "7/7 [==============================] - 7s 917ms/step - loss: 2168.5728 - accuracy: 0.6082\n",
      "Epoch 16/40\n",
      "7/7 [==============================] - 7s 908ms/step - loss: 2148.9424 - accuracy: 0.6082\n",
      "Epoch 17/40\n",
      "7/7 [==============================] - 7s 928ms/step - loss: 2125.7649 - accuracy: 0.6082\n",
      "Epoch 18/40\n",
      "7/7 [==============================] - 7s 908ms/step - loss: 2133.2217 - accuracy: 0.6082\n",
      "Epoch 19/40\n",
      "7/7 [==============================] - 7s 939ms/step - loss: 2131.8496 - accuracy: 0.6082\n",
      "Epoch 20/40\n",
      "7/7 [==============================] - 7s 961ms/step - loss: 2127.6130 - accuracy: 0.6082\n",
      "Epoch 21/40\n",
      "7/7 [==============================] - 7s 911ms/step - loss: 2123.9387 - accuracy: 0.6082\n",
      "Epoch 22/40\n",
      "7/7 [==============================] - 7s 955ms/step - loss: 2125.1479 - accuracy: 0.6082\n",
      "Epoch 23/40\n",
      "7/7 [==============================] - 7s 911ms/step - loss: 2138.9597 - accuracy: 0.6082\n",
      "Epoch 24/40\n",
      "7/7 [==============================] - 7s 911ms/step - loss: 2145.8042 - accuracy: 0.6082\n",
      "Epoch 25/40\n",
      "7/7 [==============================] - 7s 959ms/step - loss: 2121.5161 - accuracy: 0.6082\n",
      "Epoch 26/40\n",
      "7/7 [==============================] - 7s 947ms/step - loss: 2119.8777 - accuracy: 0.6082\n",
      "Epoch 27/40\n",
      "7/7 [==============================] - 6s 897ms/step - loss: 2117.5588 - accuracy: 0.6082\n",
      "Epoch 28/40\n",
      "7/7 [==============================] - 7s 917ms/step - loss: 2136.7966 - accuracy: 0.6082\n",
      "Epoch 29/40\n",
      "7/7 [==============================] - 7s 942ms/step - loss: 2132.4746 - accuracy: 0.6082\n",
      "Epoch 30/40\n",
      "7/7 [==============================] - 7s 922ms/step - loss: 2133.4077 - accuracy: 0.6082\n",
      "Epoch 31/40\n",
      "7/7 [==============================] - 7s 925ms/step - loss: 2145.6567 - accuracy: 0.6082\n",
      "Epoch 32/40\n",
      "7/7 [==============================] - 7s 936ms/step - loss: 2127.5059 - accuracy: 0.6082\n",
      "Epoch 33/40\n",
      "7/7 [==============================] - 7s 938ms/step - loss: 2122.7932 - accuracy: 0.6082\n",
      "Epoch 34/40\n",
      "7/7 [==============================] - 7s 925ms/step - loss: 2117.8108 - accuracy: 0.6082\n",
      "Epoch 35/40\n",
      "7/7 [==============================] - 7s 942ms/step - loss: 2109.2053 - accuracy: 0.6082\n",
      "Epoch 36/40\n",
      "7/7 [==============================] - 7s 936ms/step - loss: 2118.6050 - accuracy: 0.6082\n",
      "Epoch 37/40\n",
      "7/7 [==============================] - 7s 1s/step - loss: 2131.8459 - accuracy: 0.6082\n",
      "Epoch 38/40\n",
      "7/7 [==============================] - 7s 937ms/step - loss: 2106.6282 - accuracy: 0.6082\n",
      "Epoch 39/40\n",
      "7/7 [==============================] - 7s 923ms/step - loss: 2089.3213 - accuracy: 0.6082\n",
      "Epoch 40/40\n",
      "7/7 [==============================] - 7s 916ms/step - loss: 2083.8828 - accuracy: 0.6082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as red_green_model_with_percentages.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x20327861050>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the training\n",
    "train_model(r\"C:\\MINI PROJECTS\\Sem 5 for 22 November\\Images\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
